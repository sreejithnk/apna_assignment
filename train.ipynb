{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":14524226,"sourceType":"datasetVersion","datasetId":9276353},{"sourceId":722697,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":549862,"modelId":562529},{"sourceId":725594,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":549862,"modelId":562529}],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-01-17T12:59:49.290694Z","iopub.execute_input":"2026-01-17T12:59:49.290986Z","iopub.status.idle":"2026-01-17T12:59:49.308715Z","shell.execute_reply.started":"2026-01-17T12:59:49.290958Z","shell.execute_reply":"2026-01-17T12:59:49.307983Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!pip install -U bitsandbytes","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import json\nimport torch\nfrom datasets import load_dataset\nfrom transformers import (\n    AutoModelForCausalLM,\n    AutoTokenizer,\n    BitsAndBytesConfig,\n    TrainingArguments,\n    Trainer,\n)\nfrom peft import LoraConfig, get_peft_model, prepare_model_for_kbit_training\n\nMODEL_NAME = \"Qwen/Qwen2.5-0.5B-Instruct\"\nDATA_PATH = \"/kaggle/input/dataset/train.jsonl\"\nOUTPUT_DIR = \"/kaggle/working/lora-hinglish\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T08:31:46.831054Z","iopub.execute_input":"2026-01-17T08:31:46.831639Z","iopub.status.idle":"2026-01-17T08:31:46.835410Z","shell.execute_reply.started":"2026-01-17T08:31:46.831612Z","shell.execute_reply":"2026-01-17T08:31:46.834918Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\ntokenizer.pad_token = tokenizer.eos_token","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T08:31:46.836282Z","iopub.execute_input":"2026-01-17T08:31:46.836660Z","iopub.status.idle":"2026-01-17T08:31:47.256864Z","shell.execute_reply.started":"2026-01-17T08:31:46.836625Z","shell.execute_reply":"2026-01-17T08:31:47.256250Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------------------\n# Quantization (QLoRA)\n# -----------------------------\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=torch.float16,\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T08:31:47.260512Z","iopub.execute_input":"2026-01-17T08:31:47.260935Z","iopub.status.idle":"2026-01-17T08:31:47.266074Z","shell.execute_reply.started":"2026-01-17T08:31:47.260900Z","shell.execute_reply":"2026-01-17T08:31:47.265365Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = AutoModelForCausalLM.from_pretrained(\n    MODEL_NAME,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T08:31:47.267643Z","iopub.execute_input":"2026-01-17T08:31:47.267876Z","iopub.status.idle":"2026-01-17T08:33:02.721129Z","shell.execute_reply.started":"2026-01-17T08:31:47.267853Z","shell.execute_reply":"2026-01-17T08:33:02.720307Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = prepare_model_for_kbit_training(model)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T08:33:09.081909Z","iopub.execute_input":"2026-01-17T08:33:09.082948Z","iopub.status.idle":"2026-01-17T08:33:09.094924Z","shell.execute_reply.started":"2026-01-17T08:33:09.082913Z","shell.execute_reply":"2026-01-17T08:33:09.094321Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"lora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    target_modules=[\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\"],\n    lora_dropout=0.05,\n    bias=\"none\",\n    task_type=\"CAUSAL_LM\",\n)\n\nmodel = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T08:33:12.404355Z","iopub.execute_input":"2026-01-17T08:33:12.405037Z","iopub.status.idle":"2026-01-17T08:33:12.701056Z","shell.execute_reply.started":"2026-01-17T08:33:12.405003Z","shell.execute_reply":"2026-01-17T08:33:12.700431Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------------------\n# Dataset\n# -----------------------------\nimport json\nfrom datasets import load_dataset\n\n# -----------------------------\n# Dataset formatting function\n# -----------------------------\ndef format_example(example):\n    system = (\n        \"You are an information extraction system.\\n\"\n        \"Rules:\\n\"\n        \"- Output ONLY valid JSON.\\n\"\n        \"- Do NOT add explanations.\\n\"\n        \"- Hindi words must be in Devanagari.\\n\"\n        \"- English words must remain in Latin.\\n\"\n        \"- Follow the schema exactly.\\n\\n\"\n    )\n\n    user = f\"{example['instruction']}\\n\\nInput:\\n{example['input']}\\n\"\n    assistant = json.dumps(example[\"output\"], ensure_ascii=False)\n\n    text = (\n        \"<s>[SYSTEM]\\n\" + system +\n        \"[USER]\\n\" + user +\n        \"[ASSISTANT]\\n\" + assistant + \"</s>\"\n    )\n\n    # Tokenize the text\n    encodings = tokenizer(\n        text,\n        truncation=True,\n        padding=\"max_length\",\n        max_length=1024,\n    )\n\n    # For causal LM, labels = input_ids\n    # Optional: mask padding tokens with -100 to ignore in loss\n    encodings[\"labels\"] = [\n        [(token if token != tokenizer.pad_token_id else -100) for token in encodings[\"input_ids\"]]\n    ]\n\n    return encodings\n\n# -----------------------------\n# Load and format dataset\n# -----------------------------\ndataset = load_dataset(\"json\", data_files=DATA_PATH, split=\"train\")\ndataset = dataset.map(format_example, remove_columns=dataset.column_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T08:33:14.986710Z","iopub.execute_input":"2026-01-17T08:33:14.987414Z","iopub.status.idle":"2026-01-17T08:33:17.013972Z","shell.execute_reply.started":"2026-01-17T08:33:14.987384Z","shell.execute_reply":"2026-01-17T08:33:17.013156Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# -----------------------------\n# Training\n# -----------------------------\ntraining_args = TrainingArguments(\n    output_dir=OUTPUT_DIR,\n    per_device_train_batch_size=1,\n    gradient_accumulation_steps=2,\n    learning_rate=2e-4,\n    num_train_epochs=3,\n    fp16=True,\n    logging_steps=25,\n    save_strategy=\"epoch\",\n    save_total_limit=2,\n    optim=\"adamw_torch\",\n    lr_scheduler_type=\"cosine\",\n    warmup_ratio=0.05,\n    report_to=\"none\",\n)\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=dataset,\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T08:33:20.802086Z","iopub.execute_input":"2026-01-17T08:33:20.802685Z","iopub.status.idle":"2026-01-17T08:33:20.861785Z","shell.execute_reply.started":"2026-01-17T08:33:20.802650Z","shell.execute_reply":"2026-01-17T08:33:20.860985Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"trainer.train()\n\nmodel.save_pretrained(OUTPUT_DIR)\ntokenizer.save_pretrained(OUTPUT_DIR)\n\nprint(\"âœ… LoRA fine-tuning complete\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T09:03:25.155030Z","iopub.execute_input":"2026-01-17T09:03:25.155696Z","iopub.status.idle":"2026-01-17T09:03:32.672726Z","shell.execute_reply.started":"2026-01-17T09:03:25.155664Z","shell.execute_reply":"2026-01-17T09:03:32.667322Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-17T12:59:54.968544Z","iopub.execute_input":"2026-01-17T12:59:54.968842Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}